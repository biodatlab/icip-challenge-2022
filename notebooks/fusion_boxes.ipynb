{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import nms, soft_nms, non_maximum_weighted, weighted_boxes_fusion\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.autonotebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_DIR = \"/home/tupleteam/git/chula_icip/test/data\"\n",
    "\n",
    "NMS_THRESH=0.55\n",
    "BOX_THRESH=0.55\n",
    "PP_THRESH=0.55\n",
    "\n",
    "# 2022-05-20\n",
    "result_files = [\n",
    "    {\n",
    "        \"name\": \"htc-x101-64x4d\",\n",
    "        \"path\": \"predictions/best_20220520/htc-x101-64x4d-fpn-dconv_pseudo-fusion_mIoU=0.928_threshold=0.1.json\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"htc-hrnet-w32\",\n",
    "        \"path\": \"predictions/best_20220520/htc-hrnet-w32_pseudo-fusion_mIoU=0.928_threshold=0.1.json\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"tood-r101\",\n",
    "        \"path\": \"predictions/best_20220520/tood-r101-dconv_12epoch_pseudo-fusion_mIoU=0.926_threshold=0.1.json\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hrnetv2p\",\n",
    "        \"path\": \"predictions/best_20220520/cascade-rcnn-hrnetv2p-w32_10epoch_pseudo-fusion_mIoU=0.927_threshold=0.1.json\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "        {\n",
    "        \"name\": \"gfl-r101\",\n",
    "        \"path\": \"predictions/best_20220520/gfl-r101-dcn_pseudo-fusion_mIoU=0.923_threshod=0.1.json\",\n",
    "        \"weight\": 0.2,\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     39,
     50
    ]
   },
   "outputs": [],
   "source": [
    "def format_annotations(file_path):\n",
    "    \n",
    "    try:\n",
    "        annotations = json.load(open(file_path, \"r\"))[\"annotations\"]\n",
    "    except TypeError as e:\n",
    "        annotations = json.load(open(file_path, \"r\"))\n",
    "    \n",
    "    data = {}\n",
    "    for ann in annotations:\n",
    "        \n",
    "        try:\n",
    "            file_name = ann[\"file_name\"]\n",
    "        except KeyError as e: \n",
    "            image_id = ann[\"image_id\"]\n",
    "            file_name = \"{}\".format(image_id).zfill(4)\n",
    "            file_name = f\"{file_name}.jpg\"\n",
    "        \n",
    "        image_info = image_dict[file_name]\n",
    "        \n",
    "        orig_bbox = ann[\"bbox\"]\n",
    "        bbox = norm_coco_bbox(ann[\"bbox\"], image_info[\"width\"], image_info[\"height\"])\n",
    "        score = ann[\"score\"]\n",
    "        category_id = ann[\"category_id\"]\n",
    "\n",
    "        if file_name not in data.keys():\n",
    "            data[file_name] = {\n",
    "                \"original_boxes_list\": [],\n",
    "                \"boxes_list\": [],\n",
    "                \"labels_list\": [],\n",
    "                \"scores_list\": [],\n",
    "            }\n",
    "\n",
    "        data[file_name][\"original_boxes_list\"].append(orig_bbox)\n",
    "        data[file_name][\"boxes_list\"].append(bbox)\n",
    "        data[file_name][\"labels_list\"].append(category_id)\n",
    "        data[file_name][\"scores_list\"].append(score)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def norm_coco_bbox(coco_bbox, w, h):\n",
    "    # coco bbox format: [x,y,width,height]\n",
    "    # Coordinates for boxes expected to be normalized e.g in range [0; 1]. Order: x1, y1, x2, y2.\n",
    "    \n",
    "    x1 = coco_bbox[0] / w\n",
    "    x2 = x1 + (coco_bbox[2] / w)\n",
    "    y1 = coco_bbox[1] / h\n",
    "    y2 = y1 + (coco_bbox[3] / h)\n",
    "    \n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def convert_norm_box_to_coco_bbox(norm_box, w, h):\n",
    "    \n",
    "    bbox = [\n",
    "            norm_box[0] * w,\n",
    "            norm_box[1] * h,\n",
    "            (norm_box[2] - norm_box[0]) * w,\n",
    "            (norm_box[3] - norm_box[1]) * h,\n",
    "        ]\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image witdh, height dict\n",
    "\n",
    "image_dict = {}\n",
    "image_paths = sorted(glob(f\"{TEST_IMAGE_DIR}/*.jpg\"))\n",
    "\n",
    "coco_images = []\n",
    "\n",
    "image_id = 0\n",
    "for p in tqdm(image_paths):\n",
    "    file_name = os.path.basename(p)\n",
    "    \n",
    "    im = Image.open(p)\n",
    "    w, h = im.size\n",
    "    \n",
    "    image_id += 1\n",
    "    \n",
    "    image_dict[file_name] = {\"width\": w, \"height\": h, \"image_id\": image_id}\n",
    "    \n",
    "    coco_images.append({\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": file_name,\n",
    "        \"height\": h,\n",
    "        \"width\": w,\n",
    "        \"license\": 1,\n",
    "        \"coco_url\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format annotation each models before fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_annotation_dict = {}\n",
    "file_paths = []\n",
    "for rf in result_files:\n",
    "    \n",
    "    print(rf[\"path\"])\n",
    "    \n",
    "    format_ann = format_annotations(rf[\"path\"])\n",
    "    \n",
    "    format_annotation_dict[rf[\"name\"]] = format_ann\n",
    "    \n",
    "    file_paths.extend(format_ann.keys())\n",
    "    \n",
    "uniq_file_paths = sorted(list(set(file_paths)))\n",
    "len(uniq_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {r[\"name\"]: r[\"weight\"] for r in result_files}\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fusion(image_names, iou_thr, skip_box_thr):\n",
    "    fusions_dict = {}\n",
    "\n",
    "    for path in tqdm(image_names):\n",
    "\n",
    "        boxes_list = []\n",
    "        scores_list = []\n",
    "        labels_list = []\n",
    "        weights = []\n",
    "\n",
    "        for model_name, format_ann in format_annotation_dict.items():\n",
    "            #print(model_name)\n",
    "\n",
    "            info = format_ann.get(path)\n",
    "\n",
    "            if not info:\n",
    "                # no prediction for this model\n",
    "                continue\n",
    "\n",
    "            boxes_list.append(info[\"boxes_list\"])\n",
    "            scores_list.append(info[\"scores_list\"])\n",
    "            labels_list.append(info[\"labels_list\"])\n",
    "            weights.append(weight_dict.get(model_name))\n",
    "\n",
    "        if len(boxes_list) < 4:\n",
    "            print(path, len(boxes_list) )\n",
    "            print(labels_list)\n",
    "            print(scores_list)\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "        boxes, scores, labels = weighted_boxes_fusion(\n",
    "                                    boxes_list, \n",
    "                                    scores_list, \n",
    "                                    labels_list, \n",
    "                                    weights=weights, \n",
    "                                    iou_thr=iou_thr, \n",
    "                                    skip_box_thr=skip_box_thr\n",
    "                                )\n",
    "\n",
    "        fusions_dict[path] = {\n",
    "            \"boxes\": boxes,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "        \n",
    "    return fusions_dict\n",
    "\n",
    "fusions_dict = process_fusion(uniq_file_paths[:], NMS_THRESH, BOX_THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert fusions_dict back to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "cnt_id = 0\n",
    "cnt_lower_threshold = 0\n",
    "threshold = PP_THRESH\n",
    "\n",
    "for file_name, info in fusions_dict.items():\n",
    "    #print(file_name)\n",
    "    \n",
    "    image_info = image_dict[file_name]\n",
    "    \n",
    "    score_indexes = np.argsort(info[\"scores\"])\n",
    "    \n",
    "    if len(info[\"scores\"]) == 0:\n",
    "        continue\n",
    "    \n",
    "    # filter max score\n",
    "    index = np.argmax(info[\"scores\"])\n",
    "    \n",
    "    cnt_annotate = 0\n",
    "    found_category_id = None\n",
    "    for index in score_indexes:\n",
    "    \n",
    "        label = info[\"labels\"][index]\n",
    "        score = info[\"scores\"][index]\n",
    "        box = info[\"boxes\"][index]\n",
    "\n",
    "        if score < threshold:\n",
    "            continue\n",
    "\n",
    "        category_id = int(label)\n",
    "        coco_bbox = convert_norm_box_to_coco_bbox(box, image_info[\"width\"], image_info[\"height\"])\n",
    "\n",
    "        item = {\n",
    "            \"id\": cnt_id,\n",
    "            \"bbox\": coco_bbox,\n",
    "            \"category_id\": category_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"score\": float(score),\n",
    "        }\n",
    "        items.append(item)\n",
    "\n",
    "        cnt_id += 1\n",
    "        cnt_annotate += 1\n",
    "        found_category_id = category_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing prediction with selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pred_images = set(image_dict.keys()) - set(\n",
    "    list(map(lambda r: r[\"file_name\"], items))\n",
    ")\n",
    "len(missing_pred_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"tood-r101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_items = []\n",
    "for missing_im in missing_pred_images:\n",
    "    file_name = missing_im\n",
    "    print(file_name)\n",
    "    \n",
    "    image_info = image_dict[file_name]\n",
    "    \n",
    "    info = format_annotation_dict[selected_model].get(file_name, None)\n",
    "    if info is None:\n",
    "        print(\"Not found: {}\".format(file_name))\n",
    "        continue\n",
    "    \n",
    "    # filter max score\n",
    "    index = np.argmax(info[\"scores_list\"])\n",
    "    \n",
    "    label = info[\"labels_list\"][index]\n",
    "    score = info[\"scores_list\"][index]\n",
    "    box = info[\"boxes_list\"][index]\n",
    "    category_id = int(label)\n",
    "\n",
    "    coco_bbox = convert_norm_box_to_coco_bbox(box, image_info[\"width\"], image_info[\"height\"])\n",
    "\n",
    "    item = {\n",
    "            \"id\": cnt_id,\n",
    "            \"bbox\": coco_bbox,\n",
    "            \"category_id\": category_id,\n",
    "            \"file_name\": missing_im,\n",
    "            \"score\": float(score),\n",
    "        }\n",
    "    items.append(item)\n",
    "    cnt_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_output = {\"annotations\": items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(submission_output, open(\"submission_fusion_20220530_01_thr={}.json\".format(threshold), \"w\"), indent=2, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
